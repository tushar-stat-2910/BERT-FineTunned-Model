{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f7d01c73",
   "metadata": {},
   "source": [
    "conda env list\n",
    "conda create -n test\n",
    "y\n",
    "conda activate test\n",
    "python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc65fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Apply One-Hot Encoding to the 'TAG' column and convert it to an array\n",
    "labels = ohe.fit_transform(df[['TAG']])\n",
    "\n",
    "# 'labels' is now a NumPy array where each row corresponds to the one-hot encoded vector for the 'TAG'\n",
    "print(labels.shape)  # This will print the shape of the encoded label array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_ids = np.zeros(len(df), 512)\n",
    "x_attn_mask = np.zeros(len(df), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(df, input_id_arr, attn_mask_arr, tokenizer):\n",
    "    for i, text in enumerate(df['cleaned_data']): \n",
    "        # Tokenize the text\n",
    "        tokenized_text = tokenizer.encode_plus( \n",
    "            text, \n",
    "            max_length=512,  # Ensure tokenized sentence is up to 512 tokens\n",
    "            padding='max_length',  # Pads to the max length of 512 tokens\n",
    "            truncation=True,  # Truncates sentences longer than 512 tokens\n",
    "            return_tensors='tf'#'np'  # Return NumPy arrays for compatibility\n",
    "        )\n",
    "        # Fill in the arrays with tokenized input_ids and attention masks\n",
    "        input_id_arr[i, :] = tokenized_text['input_ids'][0]\n",
    "        attn_mask_arr[i, :] = tokenized_text['attention_mask'][0]\n",
    "    \n",
    "    return input_id_arr, attn_mask_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b473fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_ids, X_attn_masks = generate_training_data(df, input_id_arr, attn_mask_arr, tokenizer)\n",
    "\n",
    "print(input_id_arr.shape)  # Output: (num_samples, 512)\n",
    "print(attn_mask_arr.shape)  # Output: (num_samples, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming X_input_ids, X_attn_masks, and labels are NumPy arrays\n",
    "# Example: X_input_ids.shape = (num_samples, 512), labels.shape = (num_samples,)\n",
    "\n",
    "# Create a TensorFlow dataset from the input arrays\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))\n",
    "\n",
    "# Take a sample (first batch) from the dataset\n",
    "for input_ids, attn_mask, label in dataset.take(1):\n",
    "    print(f\"Input IDs: {input_ids.numpy()}\")\n",
    "    print(f\"Attention Mask: {attn_mask.numpy()}\")\n",
    "    print(f\"Label: {label.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbbb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prefetching to the dataset\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of samples in the dataset\n",
    "num_samples = len(df)\n",
    "\n",
    "# Calculate train size (80% of the dataset)\n",
    "train_size = int(num_samples * 0.8)  # Calculate 80% of total samples\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_dataset = dataset.take(train_size)  # First 80% for training\n",
    "test_dataset = dataset.skip(train_size)    # Remaining 20% for testing\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f\"Training dataset size: {len(list(train_dataset))}\")  # Convert to list to count\n",
    "print(f\"Testing dataset size: {len(list(test_dataset))}\")    # Convert to list to count\n",
    "\n",
    "# Check the sizes of the datasets\n",
    "train_size_count = sum(1 for _ in train_dataset)\n",
    "test_size_count = sum(1 for _ in test_dataset)\n",
    "\n",
    "print(f\"Training dataset size: {train_size_count}\")\n",
    "print(f\"Testing dataset size: {test_size_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eaea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Define the input layers\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# Get the BERT embeddings (pooled output [CLS] token)\n",
    "bert_embds = model(input_ids, attention_mask=attn_masks)[1]\n",
    "\n",
    "# Dropout layer after BERT output\n",
    "dr_layer = tf.keras.layers.Dropout(0.3, name='dropout1')(bert_embds)\n",
    "\n",
    "# Intermediate Dense layer\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer1')(dr_layer)\n",
    "\n",
    "# Another Dropout layer after intermediate layer\n",
    "dr_layer = tf.keras.layers.Dropout(0.3, name='dropout2')(intermediate_layer)\n",
    "\n",
    "# Output layer for classification (9 classes, softmax activation)\n",
    "output_layer = tf.keras.layers.Dense(9, activation='softmax', name='output_layer')(dr_layer)\n",
    "\n",
    "# Define the classification model\n",
    "classification_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "\n",
    "# Show the model summary\n",
    "classification_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b88ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                             loss='categorical_crossentropy',\n",
    "                             metrics=[tf.keras.metrics.Precision()]))\n",
    "# metrics=[tf.keras.metrics.Precision(), 'accuracy']\n",
    "\n",
    "#EarlyStoppping\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "#classification_model.fit(train_dataset, validation_data=test_dataset, epochs=3, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ade8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.fit(train_dataset, validation_data=test_dataset, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9df565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = classification_model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "# Evaluate the model on the training dataset\n",
    "train_loss, train_accuracy = classification_model.evaluate(train_dataset)\n",
    "print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "classification_model.save('bert_classification_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dc32451",
   "metadata": {},
   "source": [
    "metrics = classification_model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {metrics[0]}, Test Accuracy: {metrics[1]}, Precision: {metrics[2]}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc2b354f",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "y_pred = np.argmax(classification_model.predict(test_dataset), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cbe1f",
   "metadata": {},
   "source": [
    "##### confusion matrix for train dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f7af2d3",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict classes for the training dataset\n",
    "y_train_pred = np.argmax(classification_model.predict(train_dataset), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cbfd19d",
   "metadata": {},
   "source": [
    "# Extract true labels from the training dataset\n",
    "y_train_true = np.concatenate([y for _, y in train_dataset], axis=0)\n",
    "y_train_true = np.argmax(y_train_true, axis=1)  # Convert one-hot encoded labels to class labels\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_train_true, y_train_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix for Training Data')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62e73142",
   "metadata": {},
   "source": [
    "y_train_pred = []\n",
    "y_train_true = []\n",
    "\n",
    "# Loop through batches in the training dataset\n",
    "for batch in train_dataset:\n",
    "    inputs, labels = batch\n",
    "    predictions = classification_model.predict(inputs)  # Get predictions\n",
    "    y_train_pred.append(np.argmax(predictions, axis=1))  # Convert probabilities to predicted class labels\n",
    "    y_train_true.append(np.argmax(labels, axis=1))  # Convert one-hot encoded true labels to class labels\n",
    "\n",
    "    \n",
    "# Concatenate the list of arrays into a single array\n",
    "y_train_pred = np.concatenate(y_train_pred)\n",
    "y_train_true = np.concatenate(y_train_true)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_train_true, y_train_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix for Training Data (Batches)')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3277f853",
   "metadata": {},
   "source": [
    "# Save the model after training\n",
    "classification_model.save('bert_classification_model.h5')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d50a7cb",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('bert_classification_model.h5')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c7bc880",
   "metadata": {},
   "source": [
    "# Assuming `out_of_time_data` is a DataFrame containing new text data for prediction\n",
    "out_of_time_input_ids = np.zeros((len(out_of_time_data), 512))\n",
    "out_of_time_attn_mask = np.zeros((len(out_of_time_data), 512))\n",
    "\n",
    "# Use the same tokenizer to process out-of-time data\n",
    "for i, text in enumerate(out_of_time_data['cleaned_data']): \n",
    "    tokenized_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    out_of_time_input_ids[i, :] = tokenized_text.input_ids\n",
    "    out_of_time_attn_mask[i, :] = tokenized_text.attention_mask\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1135b12",
   "metadata": {},
   "source": [
    "# Make predictions on out-of-time data\n",
    "predictions = loaded_model.predict([out_of_time_input_ids, out_of_time_attn_mask])\n",
    "\n",
    "# Get the predicted class labels (using argmax to convert probabilities to class labels)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# If you want the predicted probabilities, you can simply use the `predictions` array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e81116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "NewsClassificationBERTModel = load_model('bert_classification_model.h5')\n",
    "\n",
    "# Prepare out-of-time data using the tokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float32),  # Corrected tf.float64 to tf.float32 for consistency\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float32)\n",
    "    }\n",
    "\n",
    "# Prediction function\n",
    "def make_predictions(model, processed_data, classes=list(np.unique(df['TAG']))):\n",
    "    probs = model.predict([processed_data['input_ids'], processed_data['attention_mask']])[0]\n",
    "    return classes[np.argmax(probs)]\n",
    "\n",
    "# Test data example (ensure test_data is preprocessed similarly to training data)\n",
    "test_excerpts = test_data['cleaned_data'].to_list()  # Assuming 'cleaned_data' is the column in test_data\n",
    "\n",
    "# Making predictions on out-of-time data\n",
    "predicted = []\n",
    "for i in test_excerpts:\n",
    "    processed_data = prepare_data(i, tokenizer)\n",
    "    result = make_predictions(NewsClassificationBERTModel, processed_data)\n",
    "    predicted.append(result)\n",
    "\n",
    "# Adding predictions to the test_data DataFrame\n",
    "test_data['predicted'] = predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a432b440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "ab = []\n",
    "ab.extend(range(10))\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad1dd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "input_ids = np.array([[101, 7592, 2082, 2003, 102, 0, 0, 0]])  # Example input IDs\n",
    "attention_mask = np.array([[1, 1, 1, 1, 1, 0, 0, 0]])  # Example attention mask\n",
    "input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1f29d",
   "metadata": {},
   "source": [
    "#### Method to retrive original texts using the input_id's and attenstion_mask"
   ]
  },
  {
   "cell_type": "raw",
   "id": "559199e5",
   "metadata": {},
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Sample input IDs and attention mask\n",
    "input_ids = np.array([[101, 7592, 2082, 2003, 102, 0, 0, 0]])  # Example input IDs\n",
    "attention_mask = np.array([[1, 1, 1, 1, 1, 0, 0, 0]])  # Example attention mask\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Decode the input IDs\n",
    "def retrieve_original_text(input_ids, attention_mask, tokenizer):\n",
    "    # Loop through each example\n",
    "    original_texts = []\n",
    "    for i in range(input_ids.shape[0]):\n",
    "        # Get the current input ID and attention mask\n",
    "        current_input_id = input_ids[i]\n",
    "        current_attention_mask = attention_mask[i]\n",
    "        \n",
    "        # Only consider tokens where attention_mask is 1\n",
    "        valid_tokens = current_input_id[current_attention_mask == 1]\n",
    "        \n",
    "        # Decode to get original text\n",
    "        original_text = tokenizer.decode(valid_tokens, skip_special_tokens=True)\n",
    "        original_texts.append(original_text)\n",
    "    \n",
    "    return original_texts\n",
    "\n",
    "# Retrieve the original texts\n",
    "original_texts = retrieve_original_text(input_ids, attention_mask, tokenizer)\n",
    "\n",
    "# Print the result\n",
    "print(original_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef3a37",
   "metadata": {},
   "source": [
    "### END-to-END Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c5ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "     ---------------------------------------- 9.9/9.9 MB 389.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "     ------------------------------------ 436.4/436.4 kB 827.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.0-cp39-none-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 423.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp39-none-win_amd64.whl (286 kB)\n",
      "     ------------------------------------ 286.1/286.1 kB 631.2 kB/s eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "     ------------------------------------ 179.3/179.3 kB 433.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wwwtu\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "Successfully installed fsspec-2024.9.0 huggingface-hub-0.25.1 safetensors-0.4.5 tokenizers-0.20.0 transformers-4.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "\n",
    "# # Step 1: Load the pre-trained BERT tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# # Step 2: Load the pre-trained BERT model\n",
    "# bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d2f5d54",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Load and Store indices\n",
    "df = pd.read_excel('data.xlsx')  # Load your dataset\n",
    "df['original_index'] = df.index  # Save original indexes\n",
    "\n",
    "# Preprocess data \n",
    "#Do not make text lower cased as using cased model of bert\n",
    "\n",
    "df['cleaned_data'] = df['text_column']  # Assuming your text is in 'text_column'\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')   #We are  seeing case of text eg: Apple and apple are fifferentrly treated\n",
    "\n",
    "# Function to generate input IDs and attention masks\n",
    "def generate_data(df, input_id_arr, attn_mask_arr, tokenizer):\n",
    "    for i, text in enumerate(df['cleaned_data']): \n",
    "        # Tokenize the text\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text, \n",
    "            max_length=512,  # Ensure tokenized sentence is up to 512 tokens\n",
    "            padding='max_length',  # Pads to the max length of 512 tokens\n",
    "            truncation=True,  # Truncates sentences longer than 512 tokens\n",
    "            return_tensors='np'  # Return NumPy arrays for compatibility \n",
    "        )\n",
    "        # Fill in the arrays with tokenized input_ids and attention masks\n",
    "        input_id_arr[i, :] = tokenized_text['input_ids']\n",
    "        attn_mask_arr[i, :] = tokenized_text['attention_mask']\n",
    "        \n",
    "    print(\"\\n Total Number of text tokenized : \", i+1)\n",
    "    return input_id_arr, attn_mask_arr\n",
    "\n",
    "#input_id_arr[i, :] = tokenized_text['input_ids'][0];    attn_mask_arr[i, :] = tokenized_text['attention_mask'][0]\n",
    "\n",
    "# Prepare input IDs and attention masks\n",
    "X_input_ids = np.zeros((len(df), 512))                            #If want to apply on the discription column then 512 need to increase\n",
    "X_attn_masks = np.zeros((len(df), 512))\n",
    "X_input_ids, X_attn_masks = generate_data(df, X_input_ids, X_attn_masks, tokenizer)\n",
    "\n",
    "print(X_input_ids.shape)  # Output: (num_samples, 512) / (nrow_of_data,512)\n",
    "print(X_attn_masks.shape)  # Output: (num_samples, 512) / (nrow_of_data,512)\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Label encoding\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "# Apply One-Hot Encoding to the 'TAG' column and convert it to an array\n",
    "labels = ohe.fit_transform(df[['TAG']]).toarray()\n",
    "# 'labels' is now a NumPy array where each row corresponds to the one-hot encoded vector for the 'TAG'\n",
    "print(labels.shape)  # labels.shape = (num_samples,)\n",
    "\n",
    "#^^^^^^^^^^\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Create TensorFlow dataset  from the input arrays with indexes\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels_in_sample, df_in_sample['original_index'].values))\n",
    "\n",
    "\n",
    "# Take a sample (first batch) from the dataset\n",
    "for input_ids, attn_mask, label in dataset.take(1):\n",
    "    print(f\"Input IDs: {input_ids.numpy()}\")\n",
    "    print(f\"Attention Mask: {attn_mask.numpy()}\")\n",
    "    print(f\"Label: {label.numpy()}\")\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Add prefetching to the dataset\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#Splitting data into train and test\n",
    "# Calculate train size (80% of the In_ Sample_dataset)\n",
    "train_size = int(len(df_in_sample) * 0.8)\n",
    "\n",
    "# Create training and testing datasets \n",
    "train_dataset = dataset.take(train_size).shuffle(buffer_size=1000).batch(32, drop_remainder=True)  # First 80% for training\n",
    "test_dataset = dataset.skip(train_size).batch(32, drop_remainder=True)  # Remaining 20% for testing\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f\"Training dataset size: {len(list(train_dataset))}\")  # Convert to list to count\n",
    "print(f\"Testing dataset size: {len(list(test_dataset))}\")    # Convert to list to count\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Obtaining training and Testing data Index and then train and test true labels\n",
    "train_indexes = [example[3].numpy() for example in train_dataset]\n",
    "train_true_labels = labels_in_sample[train_indexes]\n",
    "test_indexes = [example[3].numpy() for example in test_dataset]\n",
    "test_true_labels = labels_in_sample[test_indexes]\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# #Optional we can find true Labels using following Code\n",
    "# # 1. Extract the true labels from the train dataset\n",
    "# train_true_labels1 = np.concatenate([y for _, y in train_dataset], axis=0)  # true labels in one array\n",
    "\n",
    "# # 2. Extract the true labels from the test dataset\n",
    "# test_true_labels1 = np.concatenate([y for _, y in test_dataset], axis=0)  # true labels in one array\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Model definition\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Define the input layers\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# Get the BERT embeddings (pooled output [CLS] token)\n",
    "bert_embds = bert_model(input_ids, attention_mask=attn_masks)[1]\n",
    "\n",
    "# Dropout layer after BERT output\n",
    "dr_layer = tf.keras.layers.Dropout(0.2, name='dropout1')(bert_embds)\n",
    "\n",
    "# Intermediate Dense layer\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(dr_layer)\n",
    "\n",
    "# Another Dropout layer after intermediate layer\n",
    "dr_layer = tf.keras.layers.Dropout(0.2, name='dropout2')(intermediate_layer)\n",
    "\n",
    "# Output layer for classification (9 classes, softmax activation)\n",
    "output_layer = tf.keras.layers.Dense(labels.shape[1], activation='softmax', name='output_layer')(dr_layer)\n",
    "\n",
    "# Define the classification model\n",
    "classification_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "\n",
    "# Define the Optimizer, Loss Function and Metrics to evaluate\n",
    "classification_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                             loss='categorical_crossentropy',\n",
    "                             metrics=['accuracy', tf.keras.metrics.Precision()]))\n",
    "            #It calculates precision after each batch,might leads slightly different results than on the whole dataset after training.\n",
    "#>>>>>>>>>>>>>>>>>>>>\n",
    "#Optional Part\n",
    "# # Callbacks for early stopping and model checkpoint\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "#>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Show the model summary\n",
    "classification_model.summary()\n",
    " \n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "#Optional\n",
    "\n",
    "# # Model training with callbacks\n",
    "# classification_model.fit(\n",
    "#     train_dataset, \n",
    "#     validation_data=test_dataset, \n",
    "#     epochs=3, \n",
    "#     callbacks=[early_stopping, checkpoint],\n",
    "#     batch_size=32  # Even though it's already defined in the dataset\n",
    "# )\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Model training without callbacks\n",
    "classification_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=test_dataset, \n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "train_loss, train_accuracy, train_precision_keras  = classification_model.evaluate(train_dataset)\n",
    "test_loss, test_accuracy, test_precision_keras = classification_model.evaluate(test_dataset)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> OPTIONAL\n",
    "# print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Train Preci Keras: {train_precision_keras}\")\n",
    "# print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Test Preci keras: {test_precision_keras}\")\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Calculate precision manually using sklearn\n",
    "def Precision_Manually(true_labels, pred_labels):\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro')  # 'macro' for multi-class\n",
    "    print(f\"Precision Manually: {precision}\")\n",
    "    return(precision)\n",
    "\n",
    "\n",
    "# Make Predictions for both training and testing data\n",
    "def Make_Predictions(classification_model, dataset):\n",
    "    # 1. Get predictions from the model (logits/probabilities)\n",
    "    preds = classification_model.predict(dataset)\n",
    "    # 2. Convert predictions to class labels (argmax to get the predicted class)\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "    #return back Predictions\n",
    "    return(pred_labels)\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# # optional function if anyone want to make predictions in batches\n",
    "# def Make_Batch_Predictions(classification_model, dataset, batch_size=32):\n",
    "#     # Initialize a list to hold predictions\n",
    "#     all_pred_labels = []\n",
    "\n",
    "#     # Iterate over the dataset in batches\n",
    "#     for batch in dataset:\n",
    "#         # Get predictions from the model (logits/probabilities)\n",
    "#         preds = classification_model.predict(batch[0], batch_size=batch_size)  # Predict only on inputs\n",
    "#         # Convert predictions to class labels (argmax to get the predicted class)\n",
    "#         pred_labels = np.argmax(preds, axis=1)\n",
    "#         # Append the predictions to the list\n",
    "#         all_pred_labels.extend(pred_labels)\n",
    "\n",
    "#     # Convert the list to a numpy array\n",
    "#     return np.array(all_pred_labels)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "#Training and Testing Predictions\n",
    "train_pred_labels = Make_Predictions(classification_model, train_dataset)\n",
    "test_pred_labels = Make_Predictions(classification_model, test_dataset)\n",
    "\n",
    "# Calculating manual Precision\n",
    "train_precision_Man = Precision_Manually(train_true_labels, train_pred_labels)\n",
    "test_precision_Man = Precision_Manually(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Train Preci Manually: {train_precision_Man},Train Preci Keras: {train_precision_keras}\")\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Test Preci Manually: {test_precision_Man},Test Preci keras: {test_precision_keras}\")\n",
    "\n",
    "\n",
    "# Plotting Confusion matrix\n",
    "def plot_confusion_matrix(true_labels, pred_labels, title):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True labels')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Train and Test Confusion Matrices\n",
    "plot_confusion_matrix(train_true_labels, train_pred_labels, \"Train Confusion Matrix\")\n",
    "plot_confusion_matrix(test_true_labels, test_pred_labels, \"Test Confusion Matrix\")\n",
    "\n",
    "# Save the model\n",
    "classification_model.save('BERT_Cased_Classification_Model.h5') # 'bert_classification_model.h5'\n",
    "\n",
    "\n",
    "# Load the model\n",
    "NewsClassificationBERTModel = tf.keras.models.load_model('BERT_Cased_Classification_Model.h5') #,custom_objects={'TFBertModel': TFBertModel}\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f187de4a",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Sample.xlsx\")\n",
    "\n",
    "df.index= [100,283,110,421,213,758,347,564,342,999]\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46ab7d9a",
   "metadata": {},
   "source": [
    "X = df.loc[:,df.columns != 'y']\n",
    "y = df['y']\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Train-test split using out-of-sample\n",
    "df_in_sample, df_out_of_sample, labels_in_sample, labels_out_of_sample = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "df_in_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3296a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "07ba9545-6d42-4230-a7ec-8832e43606cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sports',\n",
       " 'Health',\n",
       " 'Sports',\n",
       " 'Politics',\n",
       " 'Politics',\n",
       " 'Finance',\n",
       " 'Minerals',\n",
       " 'Politics',\n",
       " 'Cinema',\n",
       " 'Minerals',\n",
       " 'Minerals',\n",
       " 'Finance',\n",
       " 'Finance',\n",
       " 'Finance',\n",
       " 'Health',\n",
       " 'Cinema',\n",
       " 'Cinema',\n",
       " 'Minerals',\n",
       " 'Cinema']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_true_labels)\n",
    "train_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0ca0f2f6-0599-4833-9399-67ba8b372f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5fe3f44c-622e-4393-a93b-9aeb0a7e40d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5\n",
       "4   0.0  0.0  0.0  0.0  0.0  1.0\n",
       "26  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "0   0.0  0.0  0.0  0.0  0.0  1.0\n",
       "12  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "11  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "17  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "20  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "13  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "6   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "21  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "23  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "16  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "18  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "15  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "28  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "7   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "9   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "22  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5   1.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_in_sample_encoded_df.loc[train_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f9b2e8ca-f4c7-4170-80c7-283a544bbefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cinema', 'Finance', 'Health', 'Minerals', 'Politics', 'Sports']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "396e4427-c1ef-4145-a6ae-32eef1f42daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sports', 'Health', 'Sports', 'Politics', 'Politics', 'Finance',\n",
       "       'Minerals', 'Politics', 'Cinema', 'Minerals', 'Minerals',\n",
       "       'Finance', 'Finance', 'Finance', 'Health', 'Cinema', 'Cinema',\n",
       "       'Minerals', 'Cinema'], dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels_indices = np.argmax(labels_in_sample_encoded_df.loc[train_indexes].values, axis=1)\n",
    "    # 3. Convert indices to actual class names\n",
    "classes = ohe.categories_[0]\n",
    "pred_labels = classes[pred_labels_indices]\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63e999-5df7-49df-bffa-4b89950ff10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5f4b2-7829-432c-b05c-d3508b8bec16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418d6ba-c99f-483b-ac23-450357fc1694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d37bc-2f04-4073-9b1c-6f74d4c4b86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793f121c-db75-44d4-8383-0170009c13fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afb069-db0d-40d0-9467-dd26b1635b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5034860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAta Cleaning\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Lowercase the text\n",
    "    #text = text.lower()\n",
    "    # 2. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # 3. Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # 4. Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # 5. Remove numbers\n",
    "    \n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # 6. Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # 7. Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def clean_column(df, col_name):\n",
    "    # Apply the clean_text function to each entry in the specified column\n",
    "    return df[col_name].apply(clean_text)\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# Function to generate input IDs and attention masks\n",
    "def generate_data(df, input_id_arr, attn_mask_arr):\n",
    "    \n",
    "    for i, text in enumerate(df['cleaned_data']): \n",
    "        # Tokenize the text\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text, \n",
    "            max_length=50,  # Ensure tokenized sentence is up to 512 tokens\n",
    "            padding='max_length',  # Pads to the max length of 512 tokens\n",
    "            truncation=True,  # Truncates sentences longer than 512 tokens\n",
    "            return_tensors='np'  # Return NumPy arrays for compatibility \n",
    "        )\n",
    "        # Fill in the arrays with tokenized input_ids and attention masks\n",
    "        input_id_arr[i, :] = tokenized_text['input_ids']\n",
    "        attn_mask_arr[i, :] = tokenized_text['attention_mask']\n",
    "        \n",
    "    print(\"\\n Total Number of text tokenized : \", i+1)\n",
    "    return input_id_arr, attn_mask_arr\n",
    "\n",
    "#input_id_arr[i, :] = tokenized_text['input_ids'][0];    attn_mask_arr[i, :] = tokenized_text['attention_mask'][0]\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "\n",
    "def Make_Predictions(classification_model, dataset, label_encoder):\n",
    "    # 1. Get predictions from the model (logits/probabilities)\n",
    "    preds = classification_model.predict(dataset)\n",
    "    # 2. Convert predictions to class labels (argmax to get the predicted class indices)\n",
    "    pred_labels_indices = np.argmax(preds, axis=1)\n",
    "    # 3. Convert indices to actual class names\n",
    "    classes = label_encoder.categories_[0]\n",
    "    pred_labels = classes[pred_labels_indices]\n",
    "    # Return back Predictions (actual class names)\n",
    "    return pred_labels\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#To make predictions   #This function has some error\n",
    "# def Make_Predictions(classification_model, dataset, label_encoder):\n",
    "#     # 1. Get predictions from the model (logits/probabilities)\n",
    "#     preds = classification_model.predict(dataset)\n",
    "#     # 2. Convert predictions to class labels (argmax to get the predicted class)\n",
    "#     pred_labels_indices = np.argmax(preds, axis=1)\n",
    "\n",
    "#     temp_encoded[np.arange(##),temp_labels_indices]=1\n",
    "#     # 3. Map predicted indices back to actual class names using the label encoder\n",
    "#     pred_labels = label_encoder.inverse_transform(pred_labels_indices.reshape(-1, 1))\n",
    "    \n",
    "#     # return back Predictions (actual class names)\n",
    "#     return pred_labels\n",
    "\n",
    "\n",
    "#Correct function\n",
    "# def Make_Predictions(classification_model, dataset, label_encoder):\n",
    "#     # 1. Get predictions from the model (logits/probabilities)\n",
    "#     preds = classification_model.predict(dataset)\n",
    "#     # 2. Convert predictions to class labels (argmax to get the predicted class indices)\n",
    "#     pred_labels_indices = np.argmax(preds, axis=1)\n",
    "#     # 3. Create a one-hot encoded array for the predicted labels\n",
    "#     num_classes = preds.shape[1]  # Number of classes is the second dimension of preds\n",
    "#     num_samples = preds.shape[0]\n",
    "#     temp_encoded = np.zeros((num_samples, num_classes), dtype=int)  # Shape (num_samples, num_classes)\n",
    "\n",
    "#     # 4. Assign 1 to the appropriate class index for each sample\n",
    "#     temp_encoded[np.arange(num_samples), pred_labels_indices] = 1\n",
    "\n",
    "#     # 5. Map predicted indices back to actual class names using the label encoder\n",
    "#     pred_labels = label_encoder.inverse_transform(temp_encoded)\n",
    "    \n",
    "#     # Return back Predictions (actual class names)\n",
    "#     return pred_labels\n",
    "\n",
    "\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "#Calculate Precision Manually\n",
    "# Calculate precision manually using sklearn\n",
    "def Precision_Manually(true_labels, pred_labels):\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro')  # 'macro' for multi-class\n",
    "    print(f\"Precision Manually: {precision}\")\n",
    "    return(precision)\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# Plotting Confusion matrix\n",
    "#FUNCTION 1\n",
    "def ConfusionMatrix(true_labels, pred_labels, title,encoder):\n",
    "    cm = confusion_matrix(true_labels,pred_labels)\n",
    "    cmd = ConfusionMatrixDisplay(cm)#,display_labels= list(encoder.categories_[0]))\n",
    "    cmd.plot()\n",
    "    plt.title(title,loc= 'center')\n",
    "    plt.show()\n",
    "\n",
    "#FUNCTION 2\n",
    "def plot_confusion_matrix(true_labels, pred_labels, title):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True labels')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.show()\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49b3787f-d283-426c-ba21-5608dcbfba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers -U\n",
    "#pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install re string \n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2a1367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Import Necessary Libraries\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from transformers import BertTokenizer, TFBertModel\n",
    "# # Tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')   #We are using case sensitive model of bert\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# #import seaborn as sns\n",
    "# from sklearn.metrics import precision_score\n",
    "# import joblib\n",
    "# import re\n",
    "# import string\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# #Download the stopwords if not already present\n",
    "# #nltk.download('stopwords')\n",
    "# stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9202e7db-ed5e-4cba-85ba-7a2fe274ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a926e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No matching packages\n"
     ]
    }
   ],
   "source": [
    "pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd519d85-b79f-4158-a556-0f1866c5557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_excel('News_Sample_data.xlsx') \n",
    "\n",
    "X = df.loc[:,df.columns != 'TAG']\n",
    "y = df['TAG']\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Train-test split using out-of-sample\n",
    "df_in_sample, df_out_of_sample, labels_in_sample, labels_out_of_sample = train_test_split(X, y, test_size=0.2, random_state=42, stratify= y)\n",
    "\n",
    "del X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e58c85-0308-46b2-84af-188f2be84ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG\n",
      "Finance     4\n",
      "Politics    4\n",
      "Cinema      4\n",
      "Health      4\n",
      "Minerals    4\n",
      "Sports      4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EXCERPT</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>402</td>\n",
       "      <td>Learning from Experience: Aswath Damodaran on ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>304</td>\n",
       "      <td>Bihar Chief Minister Nitish Kumar indicates ti...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>205</td>\n",
       "      <td>‘Kareena Kapoor will never shoot in Darjeeling...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>401</td>\n",
       "      <td>Many shades of Chinese recovery: 5 stocks from...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202</td>\n",
       "      <td>Raj Kapoor walked in ‘swinging a bottle of cha...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                            EXCERPT  original_index\n",
       "16  402  Learning from Experience: Aswath Damodaran on ...              16\n",
       "13  304  Bihar Chief Minister Nitish Kumar indicates ti...              13\n",
       "9   205  ‘Kareena Kapoor will never shoot in Darjeeling...               9\n",
       "15  401  Many shades of Chinese recovery: 5 stocks from...              15\n",
       "6   202  Raj Kapoor walked in ‘swinging a bottle of cha...               6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store indices\n",
    "df_in_sample['original_index'] = df_in_sample.index  # Save original indexes\n",
    "print(labels_in_sample.value_counts())\n",
    "df_in_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71511ba0-d855-49b5-9967-05c122f5195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EXCERPT</th>\n",
       "      <th>original_index</th>\n",
       "      <th>cleaned_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>402</td>\n",
       "      <td>Learning from Experience: Aswath Damodaran on ...</td>\n",
       "      <td>16</td>\n",
       "      <td>Learning Experience Aswath Damodaran Hubris mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>304</td>\n",
       "      <td>Bihar Chief Minister Nitish Kumar indicates ti...</td>\n",
       "      <td>13</td>\n",
       "      <td>Bihar Chief Minister Nitish Kumar indicates ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>205</td>\n",
       "      <td>‘Kareena Kapoor will never shoot in Darjeeling...</td>\n",
       "      <td>9</td>\n",
       "      <td>‘Kareena Kapoor never shoot Darjeeling’ Sujoy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>401</td>\n",
       "      <td>Many shades of Chinese recovery: 5 stocks from...</td>\n",
       "      <td>15</td>\n",
       "      <td>Many shades Chinese recovery stocks pipes wire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                            EXCERPT  original_index  \\\n",
       "16  402  Learning from Experience: Aswath Damodaran on ...              16   \n",
       "13  304  Bihar Chief Minister Nitish Kumar indicates ti...              13   \n",
       "9   205  ‘Kareena Kapoor will never shoot in Darjeeling...               9   \n",
       "15  401  Many shades of Chinese recovery: 5 stocks from...              15   \n",
       "\n",
       "                                         cleaned_data  \n",
       "16  Learning Experience Aswath Damodaran Hubris mi...  \n",
       "13  Bihar Chief Minister Nitish Kumar indicates ti...  \n",
       "9   ‘Kareena Kapoor never shoot Darjeeling’ Sujoy ...  \n",
       "15  Many shades Chinese recovery stocks pipes wire...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess data \n",
    "# Do not make text lower cased as using case sensitive model of bert\n",
    "df_in_sample['cleaned_data'] = clean_column(df_in_sample, 'EXCERPT') \n",
    "print(df_in_sample.shape)\n",
    "df_in_sample.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c53fc51-08c7-4a5d-80ae-2657a42e1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total Number of text tokenized :  24\n",
      "(24, 50)\n",
      "(24, 50)\n"
     ]
    }
   ],
   "source": [
    "# Prepare input IDs and attention masks\n",
    "X_input_ids = np.zeros((len(df_in_sample), 50))                            #If want to apply on the discription column then 512 need to increase\n",
    "X_attn_masks = np.zeros((len(df_in_sample), 50))\n",
    "X_input_ids, X_attn_masks = generate_data(df_in_sample, X_input_ids, X_attn_masks)\n",
    "\n",
    "print(X_input_ids.shape)  # Output: (num_samples, 512) / (nrow_of_data,512)\n",
    "print(X_attn_masks.shape)  # Output: (num_samples, 512) / (nrow_of_data,512)\n",
    "X_input_ids_df = pd.DataFrame(X_input_ids,index=df_in_sample.index)\n",
    "X_attn_masks_df = pd.DataFrame(X_attn_masks,index=df_in_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebe175d2-60df-4216-b8fb-e9fddd857c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5\n",
       "16  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "13  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "9   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "15  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "6   1.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label One Hot Encoding\n",
    "ohe = OneHotEncoder(sparse_output = False)\n",
    "# Apply One-Hot Encoding to the 'TAG' column and convert it to an array\n",
    "labels_in_sample_encoded = ohe.fit_transform(labels_in_sample.values.reshape(-1, 1))\n",
    "labels_in_sample_encoded_df = pd.DataFrame(labels_in_sample_encoded,index= df_in_sample.index)\n",
    "#ohe.fit_transform(labels_in_sample.to_frame()).to_array()    #ohe.fit_transform(labels_in_sample).toarray()\n",
    "# 'labels' is now a NumPy array where each row corresponds to the one-hot encoded vector for the 'TAG'\n",
    "print(labels_in_sample_encoded.shape)  # labels.shape = (num_samples,)\n",
    "labels_in_sample_encoded\n",
    "labels_in_sample_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a6f601-94ab-4ab4-b726-fbcabb86293e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Cinema', 'Finance', 'Health', 'Minerals', 'Politics', 'Sports'],\n",
      "      dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16     Finance\n",
       "13    Politics\n",
       "9       Cinema\n",
       "15     Finance\n",
       "6       Cinema\n",
       "28      Health\n",
       "20    Minerals\n",
       "11    Politics\n",
       "18     Finance\n",
       "4       Sports\n",
       "26      Health\n",
       "5       Cinema\n",
       "17     Finance\n",
       "0       Sports\n",
       "7       Cinema\n",
       "21    Minerals\n",
       "12    Politics\n",
       "22    Minerals\n",
       "23    Minerals\n",
       "25      Health\n",
       "10    Politics\n",
       "3       Sports\n",
       "2       Sports\n",
       "29      Health\n",
       "Name: TAG, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ohe.categories_)\n",
    "labels_in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472ff135-87a7-4b1b-8cae-af2ed5865de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [  101.  9681. 15843.  1249. 20543.  1324.  8732. 16848.  4047. 20164.\n",
      " 27647.  1116. 12572.  1893.  5074.  1301.  2265. 23379.   102.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "Attention Mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Label: [0. 1. 0. 0. 0. 0.]\n",
      "Original Index: 16\n",
      "Input IDs: [  101. 17301.  2534.  2110. 27453.  6620.  1324.  9392.  6653.  7057.\n",
      "   139. 25141.  5992.   102.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      "Attention Mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Label: [0. 0. 0. 0. 1. 0.]\n",
      "Original Index: 13\n"
     ]
    }
   ],
   "source": [
    "# Create TensorFlow dataset  from the input arrays with indexes\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels_in_sample_encoded, df_in_sample['original_index'].values))\n",
    "\n",
    "# # Take a sample (first batch) from the dataset\n",
    "# for input_ids, attn_mask, label in dataset.take(1):\n",
    "#     print(f\"Input IDs: {input_ids.numpy()}\")\n",
    "#     print(f\"Attention Mask: {attn_mask.numpy()}\")\n",
    "#     print(f\"Label: {label.numpy()}\")\n",
    "\n",
    "for input_ids, attn_mask, label, original_index in dataset.take(2):\n",
    "    print(f\"Input IDs: {input_ids.numpy()}\")\n",
    "    print(f\"Attention Mask: {attn_mask.numpy()}\")\n",
    "    print(f\"Label: {label.numpy()}\")\n",
    "    print(f\"Original Index: {original_index.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8f6947-bc45-4ef1-9cdc-b6ceb99938bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prefetching to the dataset\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a4b048a-1ac3-4005-a3fc-7405ca225f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 19\n",
      "Testing dataset size: 5\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train and test\n",
    "# Calculate train size (80% of the In_ Sample_dataset)\n",
    "train_size = int(len(df_in_sample) * 0.8)\n",
    "\n",
    "#Define Batch Size\n",
    "batch_size = 1\n",
    "\n",
    "# Create training and testing datasets \n",
    "train_dataset = dataset.take(train_size).shuffle(buffer_size=1000).batch(batch_size, drop_remainder=True)  # First 80% for training\n",
    "test_dataset = dataset.skip(train_size).batch(batch_size, drop_remainder=True)  # Remaining 20% for testing\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f\"Training dataset size: {len(list(train_dataset))}\")  # Convert to list to count\n",
    "print(f\"Testing dataset size: {len(list(test_dataset))}\")    # Convert to list to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67843a4c-28ba-4091-b9c9-b4e7944ff59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of train and test Indices:  19 5\n",
      "Lengths of train and test True labels:  19 5\n"
     ]
    }
   ],
   "source": [
    "# Obtaining training and Testing data Index and then train and test true labels\n",
    "# Flatten the index values (from tuples to integers)\n",
    "train_indexes = [example[3].numpy()[0] for example in train_dataset]\n",
    "test_indexes = [example[3].numpy()[0] for example in test_dataset]\n",
    "print(\"Lengths of train and test Indices: \",len(train_indexes),len(test_indexes))\n",
    "\n",
    "# Use the flattened indexes to retrieve the corresponding labels\n",
    "train_true_labels = labels_in_sample.loc[train_indexes].to_list()\n",
    "test_true_labels = labels_in_sample.loc[test_indexes].to_list()\n",
    "print(\"Lengths of train and test True labels: \",len(train_true_labels), len(test_true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4e786fc-1162-4a3e-bd30-1fc1d9c6e264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cinema', 'Sports', 'Finance', 'Minerals', 'Cinema', 'Minerals', 'Cinema', 'Health', 'Sports', 'Finance', 'Finance', 'Minerals', 'Politics', 'Politics', 'Cinema', 'Finance', 'Health', 'Politics', 'Minerals']\n",
      "['Cinema' 'Finance' 'Health' 'Minerals' 'Politics' 'Sports']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_true_labels)\n",
    "print(np.unique(train_true_labels))\n",
    "(df.loc[train_indexes,'TAG']== train_true_labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71e22ed-1e84-450c-b8af-049eefe721c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 50)\n",
      "(19, 50)\n",
      "(5, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>25382.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>18757.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>16383.0</td>\n",
       "      <td>21132.0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>12460.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>9368.0</td>\n",
       "      <td>5491.0</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>14627.0</td>\n",
       "      <td>9381.0</td>\n",
       "      <td>15602.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101.0</td>\n",
       "      <td>15397.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>26510.0</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>17796.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>101.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>6265.0</td>\n",
       "      <td>24920.0</td>\n",
       "      <td>14112.0</td>\n",
       "      <td>5294.0</td>\n",
       "      <td>3607.0</td>\n",
       "      <td>15362.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101.0</td>\n",
       "      <td>12707.0</td>\n",
       "      <td>18321.0</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>12933.0</td>\n",
       "      <td>5346.0</td>\n",
       "      <td>17673.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>3143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2        3        4        5        6        7   \\\n",
       "5   101.0    159.0  25382.0   1161.0  18757.0   4371.0    153.0  16383.0   \n",
       "0   101.0  12460.0    155.0   9368.0   5491.0   1524.0  14627.0   9381.0   \n",
       "17  101.0  15397.0   2385.0  26510.0   2277.0   2098.0   2319.0   2860.0   \n",
       "20  101.0   1726.0   1738.0   6265.0  24920.0  14112.0   5294.0   3607.0   \n",
       "6   101.0  12707.0  18321.0   2045.0    786.0  12933.0   5346.0  17673.0   \n",
       "\n",
       "         8       9   ...   40   41   42   43   44   45   46   47   48   49  \n",
       "5   21132.0  1248.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   15602.0  1197.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  17796.0  1160.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20  15362.0   102.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6     787.0  3143.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_input_ids.shape)\n",
    "print(X_input_ids_df.loc[train_indexes].values.shape)\n",
    "print(X_input_ids_df.loc[test_indexes].values.shape)\n",
    "X_input_ids_df.loc[train_indexes].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41cc8b0e-2793-4036-9dff-000773d86580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 50)\n",
      "(19, 50)\n",
      "(5, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...   40   41   42   43  \\\n",
       "5   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "0   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "17  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "20  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "6   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     44   45   46   47   48   49  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_attn_masks.shape)\n",
    "print(X_attn_masks_df.loc[train_indexes].values.shape)\n",
    "print(X_attn_masks_df.loc[test_indexes].values.shape)\n",
    "X_attn_masks_df.loc[train_indexes].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "886812a6-ae5f-495f-a65f-02345021747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 6)\n",
      "(19, 6)\n",
      "(5, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5\n",
       "5   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "0   0.0  0.0  0.0  0.0  0.0  1.0\n",
       "17  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "20  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "6   1.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels_in_sample_encoded.shape)\n",
    "print(labels_in_sample_encoded_df.loc[train_indexes].values.shape)\n",
    "print(labels_in_sample_encoded_df.loc[test_indexes].values.shape)\n",
    "labels_in_sample_encoded_df.loc[train_indexes].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00e2f9b5-6481-4bd2-9b39-0b0645be8e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5\n",
       "5   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "0   0.0  0.0  0.0  0.0  0.0  1.0\n",
       "17  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "20  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "6   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "21  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "7   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "28  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4   0.0  0.0  0.0  0.0  0.0  1.0\n",
       "15  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "18  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "23  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "11  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "12  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "9   1.0  0.0  0.0  0.0  0.0  0.0\n",
       "16  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "26  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "13  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "22  0.0  0.0  0.0  1.0  0.0  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_in_sample_encoded_df.loc[train_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "129beaef-c4e2-489e-aec6-aa044d3e06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset without the original_index\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'input_ids': X_input_ids_df.loc[train_indexes].values,\n",
    "        'attention_mask': X_attn_masks_df.loc[train_indexes].values\n",
    "    },\n",
    "    labels_in_sample_encoded_df.loc[train_indexes].values\n",
    ")).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# Create testing dataset without the original_index\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'input_ids': X_input_ids_df.loc[test_indexes].values,\n",
    "        'attention_mask': X_attn_masks_df.loc[test_indexes].values\n",
    "    },\n",
    "    labels_in_sample_encoded_df.loc[test_indexes].values\n",
    ")).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "debc616b-9650-432c-b244-dd98b228897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 50)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
      " )                           ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 50, 76                                           \n",
      "                             8),                                                                  \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " dropout1 (Dropout)          (None, 768)                  0         ['tf_bert_model[0][1]']       \n",
      "                                                                                                  \n",
      " intermediate_layer (Dense)  (None, 50)                   38450     ['dropout1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout2 (Dropout)          (None, 50)                   0         ['intermediate_layer[0][0]']  \n",
      "                                                                                                  \n",
      " output_layer (Dense)        (None, 6)                    306       ['dropout2[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108349028 (413.32 MB)\n",
      "Trainable params: 108349028 (413.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "#  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Define the input layers\n",
    "input_ids = tf.keras.layers.Input(shape=(50,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(50,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# Get the BERT embeddings (pooled output [CLS] token)\n",
    "bert_embds = bert_model(input_ids, attention_mask=attn_masks)[1]\n",
    "\n",
    "# Dropout layer after BERT output\n",
    "dr_layer = tf.keras.layers.Dropout(0.01, name='dropout1')(bert_embds)\n",
    "\n",
    "# Intermediate Dense layer\n",
    "intermediate_layer = tf.keras.layers.Dense(50, activation='relu', name='intermediate_layer')(dr_layer)\n",
    "\n",
    "# Another Dropout layer after intermediate layer\n",
    "dr_layer = tf.keras.layers.Dropout(0.01, name='dropout2')(intermediate_layer)\n",
    "\n",
    "# Output layer for classification (9 classes, softmax activation)\n",
    "output_layer = tf.keras.layers.Dense(np.unique(train_true_labels).shape[0], activation='softmax', name='output_layer')(dr_layer)  \n",
    "\n",
    "# Define the classification model\n",
    "classification_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "\n",
    "# Define the Optimizer, Loss Function and Metrics to evaluate\n",
    "classification_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                             loss='categorical_crossentropy',\n",
    "                             metrics=['accuracy', tf.keras.metrics.Precision()])\n",
    "            #It calculates precision after each batch,might leads slightly different results than on the whole dataset after training.\n",
    "#>>>>>>>>>>>>>>>>>>>>\n",
    "#Optional Part\n",
    "# # Callbacks for early stopping and model checkpoint\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "#>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Show the model summary\n",
    "classification_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba0f7f04-ee7f-4a20-8f84-aaa501f2899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "19/19 [==============================] - 68s 2s/step - loss: 3.2732 - accuracy: 0.2105 - precision: 0.2667 - val_loss: 2.9214 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 2/3\n",
      "19/19 [==============================] - 25s 1s/step - loss: 2.9332 - accuracy: 0.1579 - precision: 0.1667 - val_loss: 1.7782 - val_accuracy: 0.2000 - val_precision: 0.0000e+00\n",
      "Epoch 3/3\n",
      "19/19 [==============================] - 25s 1s/step - loss: 2.7453 - accuracy: 0.1579 - precision: 0.1429 - val_loss: 1.9326 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x20a75be4290>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Training \n",
    "\n",
    "# Model training without callbacks\n",
    "classification_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=test_dataset, \n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Model training with callbacks\n",
    "# classification_model.fit(\n",
    "#     train_dataset, \n",
    "#     validation_data=test_dataset, \n",
    "#     epochs=3, \n",
    "#     callbacks=[early_stopping, checkpoint],\n",
    "#     batch_size=32  # Even though it's already defined in the dataset\n",
    "# )\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e783624e-f452-43bd-a0af-7c1abf8c8c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 108ms/step - loss: 1.9970 - accuracy: 0.2105 - precision: 0.0000e+00\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 1.9326 - accuracy: 0.0000e+00 - precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "train_loss, train_accuracy, train_precision_keras  = classification_model.evaluate(train_dataset)\n",
    "test_loss, test_accuracy, test_precision_keras = classification_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4859e10-992f-41f2-9d00-1da9b806c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 5s 99ms/step\n",
      "5/5 [==============================] - 1s 100ms/step\n"
     ]
    }
   ],
   "source": [
    "#Training and Testing Predictions\n",
    "train_pred_labels = Make_Predictions(classification_model, train_dataset,ohe)\n",
    "test_pred_labels = Make_Predictions(classification_model, test_dataset,ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88303801-fb2e-4c9b-a1ae-b1ee0c80e4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance',\n",
       "       'Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance',\n",
       "       'Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance',\n",
       "       'Finance'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58c07f90-8654-4fec-86f3-8f613002d877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Finance', 'Finance', 'Finance', 'Finance', 'Finance'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b6976ae-9c93-40d3-845b-384a4df7be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train True: Cinema, Train Predicted: Finance\n",
      "Test True: Health, Test Predicted: Finance\n",
      "Train True: Sports, Train Predicted: Finance\n",
      "Test True: Politics, Test Predicted: Finance\n",
      "Train True: Finance, Train Predicted: Finance\n",
      "Test True: Sports, Test Predicted: Finance\n",
      "Train True: Minerals, Train Predicted: Finance\n",
      "Test True: Sports, Test Predicted: Finance\n",
      "Train True: Cinema, Train Predicted: Finance\n",
      "Test True: Health, Test Predicted: Finance\n"
     ]
    }
   ],
   "source": [
    "# Cross-check with true labels\n",
    "for i in range(5):  # Checking the first 5 entries\n",
    "    print(f\"Train True: {train_true_labels[i]}, Train Predicted: {train_pred_labels[i]}\")\n",
    "    print(f\"Test True: {test_true_labels[i]}, Test Predicted: {test_pred_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ecad646-5861-4a87-acda-b8aa8a36a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Manually: 0.03508771929824561\n",
      "Precision Manually: 0.0\n",
      "Train Loss: 1.9969714879989624, Train Accuracy: 0.21052631735801697, Train Preci Manually: 0.03508771929824561,Train Preci Keras: 0.0\n",
      "Test Loss: 1.932621717453003, Test Accuracy: 0.0, Test Preci Manually: 0.0,Test Preci keras: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculating manual Precision\n",
    "train_precision_Man = Precision_Manually(train_true_labels, train_pred_labels)\n",
    "test_precision_Man = Precision_Manually(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Train Preci Manually: {train_precision_Man},Train Preci Keras: {train_precision_keras}\")\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Test Preci Manually: {test_precision_Man},Test Preci keras: {test_precision_keras}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b016d87-2289-4f97-8599-0fb23a55a63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance',\n",
       "       'Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance',\n",
       "       'Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance',\n",
       "       'Finance'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64e33913-920f-4622-ad93-9897adeff757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cinema', 'Sports', 'Finance', 'Minerals', 'Cinema', 'Minerals',\n",
       "       'Cinema', 'Health', 'Sports', 'Finance', 'Finance', 'Minerals',\n",
       "       'Politics', 'Politics', 'Cinema', 'Finance', 'Health', 'Politics',\n",
       "       'Minerals'], dtype='<U8')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6458255-94a1-4198-a5a5-859c29ee4f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Health', 'Politics', 'Sports', 'Sports', 'Health'], dtype='<U8')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e93d1582-b947-47a0-a26a-bc7a2db98020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Finance', 'Finance', 'Finance', 'Finance', 'Finance'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a94beebf-191a-4ce9-9cc9-0f007272aefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and Test Confusion Matrices\n",
    "ConfusionMatrix(train_true_labels, train_pred_labels, \"Train Confusion Matrix\",ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43289e64-dcf7-4f75-8254-29cdf0afa8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrix(test_true_labels, test_pred_labels, \"Test Confusion Matrix\",ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28d87f9c-db4f-437d-b85c-52671d7e4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "classification_model.save('BERT_Cased_Classification_Model.h5') #custom_objects={'TFBertModel': TFBertModel}) # 'bert_classification_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "915c9197-8101-46f9-8c8e-4ac7904c66ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OneHotEncoder.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "classification_model.save('BERT_Cased_Classification_Model.h5')\n",
    "\n",
    "# Create a separate directory to save the tokenizer\n",
    "tokenizer.save_pretrained('BERT_Tokenizer')\n",
    "\n",
    "# Save the OneHotEncoder\n",
    "joblib.dump(ohe, 'OneHotEncoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3733f31-47ab-4cf9-84ad-86586dfdd01e",
   "metadata": {},
   "source": [
    "#### Out of sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01df4151-0015-425e-880a-c598513a07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "ClassificationBERTModel = tf.keras.models.load_model(\n",
    "    'BERT_Cased_Classification_Model.h5',\n",
    "    custom_objects={'TFBertModel': TFBertModel}  # Register the custom object\n",
    ")\n",
    "\n",
    "#Load Saved Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('BERT_Tokenizer')\n",
    "\n",
    "# Load the OneHotEncoder\n",
    "ohe = joblib.load('OneHotEncoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6784e46-89e3-4c24-a84e-e80f3ab2f6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "Val_data = df_out_of_sample.copy()\n",
    "labels_Val_data = labels_out_of_sample.copy()\n",
    "Val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f8f5fdf-ddd5-47e9-b4ba-6c703c5494cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EXCERPT</th>\n",
       "      <th>cleaned_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>India vs Bangladesh: Surrounded by the ravines...</td>\n",
       "      <td>India vs Bangladesh Surrounded ravines Bihad G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>603</td>\n",
       "      <td>Marburg Virus Update: East Africa Heightens Su...</td>\n",
       "      <td>Marburg Virus Update East Africa Heightens Sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>305</td>\n",
       "      <td>PM Modi, BJP use government machinery for poll...</td>\n",
       "      <td>PM Modi BJP use government machinery poll camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>405</td>\n",
       "      <td>Wall Street Week Ahead: Investors look to earn...</td>\n",
       "      <td>Wall Street Week Ahead Investors look earnings...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                            EXCERPT  \\\n",
       "1   102  India vs Bangladesh: Surrounded by the ravines...   \n",
       "27  603  Marburg Virus Update: East Africa Heightens Su...   \n",
       "14  305  PM Modi, BJP use government machinery for poll...   \n",
       "19  405  Wall Street Week Ahead: Investors look to earn...   \n",
       "\n",
       "                                         cleaned_data  \n",
       "1   India vs Bangladesh Surrounded ravines Bihad G...  \n",
       "27  Marburg Virus Update East Africa Heightens Sur...  \n",
       "14  PM Modi BJP use government machinery poll camp...  \n",
       "19  Wall Street Week Ahead Investors look earnings...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess Data\n",
    "Val_data['cleaned_data'] = clean_column(Val_data, 'EXCERPT') \n",
    "print(Val_data.shape)\n",
    "Val_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e601a8d-f44e-4239-a1b0-93231f10c985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total Number of text tokenized :  6\n"
     ]
    }
   ],
   "source": [
    "# Prepare out-of-time data\n",
    "X1_input_ids_val = np.zeros((len(Val_data), 50))                           \n",
    "X1_attn_masks_val = np.zeros((len(Val_data), 50))\n",
    "X1_input_ids_val, X1_attn_masks_val = generate_data(Val_data, X1_input_ids_val, X1_attn_masks_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8da5ffef-05b4-422f-93a8-308b1ebcd189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode Target Variable\n",
    "labels_Val_data_encoded = ohe.transform(labels_Val_data.to_frame())\n",
    "labels_Val_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68254839-1f91-4531-9db1-155bcdf7bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Batch Size for predictions\n",
    "batch_size = 1\n",
    "\n",
    "#Create Keras Dataset\n",
    "Val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'input_ids': X1_input_ids_val,\n",
    "        'attention_mask': X1_attn_masks_val\n",
    "    },\n",
    "    labels_Val_data_encoded\n",
    ")).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7dd04602-301f-482d-b4a8-61bf05729aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Val_true_labels_arr = np.array([list(y.numpy()) for _,_,y  in Val_dataset])\n",
    "# Val_true_labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "552bb083-a7b0-438f-b295-08fc0fe1a0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sports', 'Health', 'Politics', 'Finance', 'Minerals', 'Cinema']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True Val Labels\n",
    "true_Val_Labels = labels_Val_data.to_list()\n",
    "true_Val_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de06d8a4-044b-4762-820a-464580f4160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 104ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Val_Labels = Make_Predictions(ClassificationBERTModel, Val_dataset,ohe)\n",
    "df_out_of_sample['Predicted'] = Pred_Val_Labels\n",
    "Pred_Val_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a2201f9b-c1f4-4a9d-bc22-2e6f30e3a564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample evaluation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cinema       0.00      0.00      0.00         1\n",
      "     Finance       0.17      1.00      0.29         1\n",
      "      Health       0.00      0.00      0.00         1\n",
      "    Minerals       0.00      0.00      0.00         1\n",
      "    Politics       0.00      0.00      0.00         1\n",
      "      Sports       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.17         6\n",
      "   macro avg       0.03      0.17      0.05         6\n",
      "weighted avg       0.03      0.17      0.05         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wwwtu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate out-of-time data predictions\n",
    "print(\"Out-of-sample evaluation\")\n",
    "classes = classes = ohe.categories_[0]                   #list(np.unique(labels_out_of_sample))\n",
    "print(classification_report(true_Val_Labels, Pred_Val_Labels, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "39270299-f1c8-496d-b85b-49478e1ca519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Confusion Matrix\n",
    "ConfusionMatrix(train_true_labels, train_pred_labels, \"Train Confusion Matrix\",ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f54bff39-9468-45bb-a0a7-9e1942a09a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EXCERPT</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>India vs Bangladesh: Surrounded by the ravines...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>603</td>\n",
       "      <td>Marburg Virus Update: East Africa Heightens Su...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>305</td>\n",
       "      <td>PM Modi, BJP use government machinery for poll...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>405</td>\n",
       "      <td>Wall Street Week Ahead: Investors look to earn...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>505</td>\n",
       "      <td>Indians across all age groups deficient in iro...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Minerals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>204</td>\n",
       "      <td>Nawazuddin Siddiqui mocks mindless action film...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Cinema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                            EXCERPT Predicted    Actual\n",
       "1   102  India vs Bangladesh: Surrounded by the ravines...   Finance    Sports\n",
       "27  603  Marburg Virus Update: East Africa Heightens Su...   Finance    Health\n",
       "14  305  PM Modi, BJP use government machinery for poll...   Finance  Politics\n",
       "19  405  Wall Street Week Ahead: Investors look to earn...   Finance   Finance\n",
       "24  505  Indians across all age groups deficient in iro...   Finance  Minerals\n",
       "8   204  Nawazuddin Siddiqui mocks mindless action film...   Finance    Cinema"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_of_sample['Actual'] = labels_out_of_sample\n",
    "df_out_of_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd667c-7cee-4a8f-9117-c52c60dba16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232e138-4ae1-4cf5-8d32-54b2132d91eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c617f3b-cdd4-4ed9-801b-c504d8022f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835bb15-a7a4-46a2-a5ce-6d1791b91ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd479d90-2aa6-48f1-9c4f-44301c9028e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62623b93-ec64-405e-a4c8-7be8c43d5c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020736fa-bce8-4aea-8f3c-b2d8e25c5e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8e8a8-9b99-42fe-b6ec-7bbb867ad89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Load your dataset\n",
    "df = pd.read_excel('data.xlsx') \n",
    "\n",
    "X = df_Orig.loc[:,df_Orig.columns != 'TAG']\n",
    "y = df_Orig['TAG']\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Train-test split using out-of-sample\n",
    "df_in_sample, df_out_of_sample, labels_in_sample, labels_out_of_sample = train_test_split(X, y, test_size=0.2, random_state=42, stratify= y)\n",
    "\n",
    "del X,y\n",
    "\n",
    "# Store indices\n",
    "df_in_sample['original_index'] = df_in_sample.index  # Save original indexes\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Preprocess data \n",
    "# Do not make text lower cased as using case sensitive model of bert\n",
    "\n",
    "df_in_sample['cleaned_data'] = clean_column(df, 'text_column') \n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Prepare input IDs and attention masks\n",
    "X_input_ids = np.zeros((len(df_in_sample), 512))                            #If want to apply on the discription column then 512 need to increase\n",
    "X_attn_masks = np.zeros((len(df_in_sample), 512))\n",
    "X_input_ids, X_attn_masks = generate_data(df_in_sample, X_input_ids, X_attn_masks)\n",
    "\n",
    "print(X_input_ids.shape)  # Output: (num_samples, 512) / (nrow_of_data,512)\n",
    "print(X_attn_masks.shape)  # Output: (num_samples, 512) / (nrow_of_data,512)\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#Label One Hot Encoding\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "# Apply One-Hot Encoding to the 'TAG' column and convert it to an array\n",
    "labels_in_sample_encoded = ohe.fit_transform(labels_in_sample).toarray()\n",
    "# 'labels' is now a NumPy array where each row corresponds to the one-hot encoded vector for the 'TAG'\n",
    "print(labels_in_sample_encoded.shape)  # labels.shape = (num_samples,)\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Create TensorFlow dataset  from the input arrays with indexes\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels_in_sample_encoded, df_in_sample['original_index'].values))\n",
    "\n",
    "\n",
    "# Take a sample (first batch) from the dataset\n",
    "for input_ids, attn_mask, label in dataset.take(1):\n",
    "    print(f\"Input IDs: {input_ids.numpy()}\")\n",
    "    print(f\"Attention Mask: {attn_mask.numpy()}\")\n",
    "    print(f\"Label: {label.numpy()}\")\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Add prefetching to the dataset\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#Splitting data into train and test\n",
    "# Calculate train size (80% of the In_ Sample_dataset)\n",
    "train_size = int(len(df_in_sample) * 0.8)\n",
    "\n",
    "# Create training and testing datasets \n",
    "train_dataset = dataset.take(train_size).shuffle(buffer_size=1000).batch(32, drop_remainder=True)  # First 80% for training\n",
    "test_dataset = dataset.skip(train_size).batch(32, drop_remainder=True)  # Remaining 20% for testing\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f\"Training dataset size: {len(list(train_dataset))}\")  # Convert to list to count\n",
    "print(f\"Testing dataset size: {len(list(test_dataset))}\")    # Convert to list to count\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Obtaining training and Testing data Index and then train and test true labels\n",
    "train_indexes = [example[3].numpy() for example in train_dataset]\n",
    "train_true_labels = labels_in_sample[train_indexes]\n",
    "test_indexes = [example[3].numpy() for example in test_dataset]\n",
    "test_true_labels = labels_in_sample[test_indexes]\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# #Optional we can find true Labels using following Code\n",
    "# # 1. Extract the true labels from the train dataset\n",
    "# train_true_labels1 = np.concatenate([y for _, y in train_dataset], axis=0)  # true labels in one array\n",
    "\n",
    "# # 2. Extract the true labels from the test dataset\n",
    "# test_true_labels1 = np.concatenate([y for _, y in test_dataset], axis=0)  # true labels in one array\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Model definition\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "# bert_model = transformers.from_pretrained('bert-base-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Define the input layers\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# Get the BERT embeddings (pooled output [CLS] token)\n",
    "bert_embds = bert_model(input_ids, attention_mask=attn_masks)[1]\n",
    "\n",
    "# Dropout layer after BERT output\n",
    "dr_layer = tf.keras.layers.Dropout(0.2, name='dropout1')(bert_embds)\n",
    "\n",
    "# Intermediate Dense layer\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(dr_layer)\n",
    "\n",
    "# Another Dropout layer after intermediate layer\n",
    "dr_layer = tf.keras.layers.Dropout(0.2, name='dropout2')(intermediate_layer)\n",
    "\n",
    "# Output layer for classification (9 classes, softmax activation)\n",
    "output_layer = tf.keras.layers.Dense(labels.shape[1], activation='softmax', name='output_layer')(dr_layer)\n",
    "\n",
    "# Define the classification model\n",
    "classification_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "\n",
    "# Define the Optimizer, Loss Function and Metrics to evaluate\n",
    "classification_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                             loss='categorical_crossentropy',\n",
    "                             metrics=['accuracy', tf.keras.metrics.Precision()]))\n",
    "            #It calculates precision after each batch,might leads slightly different results than on the whole dataset after training.\n",
    "#>>>>>>>>>>>>>>>>>>>>\n",
    "#Optional Part\n",
    "# # Callbacks for early stopping and model checkpoint\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "#>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Show the model summary\n",
    "classification_model.summary()\n",
    " \n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "#Optional\n",
    "\n",
    "# # Model training with callbacks\n",
    "# classification_model.fit(\n",
    "#     train_dataset, \n",
    "#     validation_data=test_dataset, \n",
    "#     epochs=3, \n",
    "#     callbacks=[early_stopping, checkpoint],\n",
    "#     batch_size=32  # Even though it's already defined in the dataset\n",
    "# )\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Model training without callbacks\n",
    "classification_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=test_dataset, \n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "train_loss, train_accuracy, train_precision_keras  = classification_model.evaluate(train_dataset)\n",
    "test_loss, test_accuracy, test_precision_keras = classification_model.evaluate(test_dataset)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> OPTIONAL\n",
    "# print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Train Preci Keras: {train_precision_keras}\")\n",
    "# print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Test Preci keras: {test_precision_keras}\")\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Make Predictions for both training and testing data\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# # optional function if anyone want to make predictions in batches\n",
    "# def Make_Batch_Predictions(classification_model, dataset, batch_size=32):\n",
    "#     # Initialize a list to hold predictions\n",
    "#     all_pred_labels = []\n",
    "\n",
    "#     # Iterate over the dataset in batches\n",
    "#     for batch in dataset:\n",
    "#         # Get predictions from the model (logits/probabilities)\n",
    "#         preds = classification_model.predict(batch[0], batch_size=batch_size)  # Predict only on inputs\n",
    "#         # Convert predictions to class labels (argmax to get the predicted class)\n",
    "#         pred_labels = np.argmax(preds, axis=1)\n",
    "#         # Append the predictions to the list\n",
    "#         all_pred_labels.extend(pred_labels)\n",
    "\n",
    "#     # Convert the list to a numpy array\n",
    "#     return np.array(all_pred_labels)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "#Training and Testing Predictions\n",
    "train_pred_labels = Make_Predictions(classification_model, train_dataset)\n",
    "test_pred_labels = Make_Predictions(classification_model, test_dataset)\n",
    "\n",
    "# Cross-check with true labels\n",
    "for i in range(5):  # Checking the first 5 entries\n",
    "    print(f\"Train True: {train_true_labels[i]}, Train Predicted: {train_pred_labels[i]}\")\n",
    "    print(f\"Test True: {test_true_labels[i]}, Test Predicted: {test_pred_labels[i]}\")\n",
    "\n",
    "# Calculating manual Precision\n",
    "train_precision_Man = Precision_Manually(train_true_labels, train_pred_labels)\n",
    "test_precision_Man = Precision_Manually(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Train Preci Manually: {train_precision_Man},Train Preci Keras: {train_precision_keras}\")\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Test Preci Manually: {test_precision_Man},Test Preci keras: {test_precision_keras}\")\n",
    "    \n",
    "# Train and Test Confusion Matrices\n",
    "plot_confusion_matrix(train_true_labels, train_pred_labels, \"Train Confusion Matrix\")\n",
    "plot_confusion_matrix(test_true_labels, test_pred_labels, \"Test Confusion Matrix\")\n",
    "\n",
    "# Save the model\n",
    "classification_model.save('BERT_Cased_Classification_Model.h5') # 'bert_classification_model.h5'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87d207-988b-42f2-96ba-ca68776fe61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Out-of-Time data\n",
    "# Save original indexes\n",
    "df_out_of_sample['original_index'] = df_out_of_sample.index\n",
    "\n",
    "# Load the model\n",
    "ClassificationBERTModel = tf.keras.models.load_model('BERT_Cased_Classification_Model.h5', custom_objects={'TFBertModel': TFBertModel})\n",
    "\n",
    "#Preprocess data\n",
    "\n",
    "\n",
    "# Prepare out-of-time data\n",
    "X1_input_ids_val = np.zeros((len(df_out_of_sample), 512))                           \n",
    "X1_attn_masks_val = np.zeros((len(df_out_of_sample), 512))\n",
    "X1_input_ids_val, X1_attn_masks_val = generate_data(df_out_of_sample, X1_input_ids, X1_attn_masks)\n",
    "\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>FOLLOWING CODE IS USEFUL IF YOU DONT WANT TO CREATE \"X_input_ids_val\" AND \"X_attn_masks_val\" SEPERATELY\n",
    "# def prepare_data(input_text, tokenizer):\n",
    "#     token = tokenizer.encode_plus(\n",
    "#         input_text,\n",
    "#         max_length=512,\n",
    "#         padding='max_length',\n",
    "#         truncation=True,\n",
    "#         return_tensors='tf'\n",
    "#     )\n",
    "#     return {'input_ids': tf.cast(token['input_ids'], tf.float64), 'attention_mask': tf.cast(token['attention_mask'], tf.float64)}\n",
    "\n",
    "# # Make predictions on out-of-time data\n",
    "# def make_predictions(model, processed_data, classes):\n",
    "#     probs = model.predict([processed_data['input_ids'], processed_data['attention_mask']])[0]\n",
    "#     return classes[np.argmax(probs)]\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "#Encode Target Variable\n",
    "labels_out_of_sample_encoded = ohe.transform(labels_out_of_sample).toarray()\n",
    "\n",
    "#Create Keras Dataset\n",
    "Val_dataset = tf.data.Dataset.from_tensor_slices((X1_input_ids, X1_attn_masks, labels_out_of_sample_encoded, df_out_of_sample['original_index'].values))\n",
    "\n",
    "#True Val Labels\n",
    "Val_true_labels_arr = np.concatenate([y for _, y in Val_dataset], axis=0)  # true labels in one array\n",
    "# Convert OHE arrays back to original labels\n",
    "Val_true_labels = ohe.inverse_transform(Val_true_labels_arr)\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Val_pred_labels = Make_Predictions(ClassificationBERTModel, Val_dataset)\n",
    "\n",
    "df_out_of_sample['predicted'] = Val_pred_labels\n",
    "\n",
    "# Evaluate out-of-time data predictions\n",
    "print(\"Out-of-sample evaluation\")\n",
    "classes = classes = ohe.categories_[0]                   #list(np.unique(labels_out_of_sample))\n",
    "print(classification_report(Val_true_labels, Val_pred_labels, target_names=classes))\n",
    "\n",
    "plot_confusion_matrix(train_true_labels, train_pred_labels, \"Train Confusion Matrix\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Classes for prediction\n",
    "# classes = list(np.unique(df['TAG']))\n",
    "# test_excerpts = df_out_of_sample['cleaned_data'].to_list()\n",
    "\n",
    "# predicted = []\n",
    "# for text in test_excerpts:\n",
    "#     processed_data = prepare_data(text, tokenizer)\n",
    "#     result = make_predictions(NewsClassificationBERTModel, processed_data, classes=classes)\n",
    "#     predicted.append(result)\n",
    "\n",
    "    \n",
    "    \n",
    "# df_out_of_sample['predicted'] = predicted\n",
    "\n",
    "# # Evaluate out-of-time data predictions\n",
    "# print(\"Out-of-sample evaluation\")\n",
    "# print(classification_report(df_out_of_sample['TAG'], df_out_of_sample['predicted'], target_names=classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
